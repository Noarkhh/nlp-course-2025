{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Laboratorium 3: RegExp vs LLM\n",
                "### Ekstrakcja informacji, polska fleksja, daty i rachunki bankowe\n",
                "\n",
                "---\n",
                "\n",
                "## Źródło danych\n",
                "\n",
                "**Korpus:** https://huggingface.co/datasets/uonlp/CulturaX\n",
                "\n",
                "**Split:** `pl`\n",
                "\n",
                "**Licencja:** MIT-like / CC (sprawdź kartę datasetu).\n",
                "\n",
                "Tu można poczytać o korpusie: https://arxiv.org/abs/2309.09400\n",
                "\n",
                "Zawiera spam, HTML i treści obcojęzyczne.\n",
                "\n",
                "Każdy i każda z Was ma obowiązek samodzielnie oczyścić dane – to element oceny laboratorium.\n",
                "\n",
                "\n",
                "\n",
                "**Cele laboratorium**\n",
                "\n",
                "1. Zaimplementowanie wyrażeń regularnych (RegExp) do wyszukiwania w języku polskim struktur takich jak:\n",
                " - daty (numeryczne i słowne),\n",
                "\n",
                " - godziny,\n",
                " - kwoty PLN,\n",
                " - e-maile, telefony, URLe,\n",
                " - numery kont bankowych (IBAN/NRB),\n",
                " - formy fleksyjne na przykładzie „człowiek” / „ludzie”.\n",
                "\n",
                "2. Zbudowanie promptów LLM (Ollama / LM Studio) wykonujących te same zadania.\n",
                "\n",
                "3. Porównanie skuteczności i czasu pracy RegExp vs LLM.\n",
                "\n",
                "4. Przygotowanie raportu i propozycji rozwiązania hybrydowego."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Przygotowanie środowiska\n",
                "\n",
                "### Instalacje\n",
                "Poniższe biblioteki są wymagane do wykonania laboratorium. Dodatkowo instalujemy `ollama` do komunikacji z LLM oraz `beautifulsoup4` i `langdetect` do skuteczniejszego czyszczenia danych."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install datasets regex pandas matplotlib rapidfuzz\n",
                "!pip install langdetect beautifulsoup4 ollama"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Objaśnienia bibliotek\n",
                "\n",
                "`datasets` -- umożliwia łatwe pobieranie i przetwarzanie dużych zbiorów danych (datasetów) w języku Python z `HuggingDace`.\n",
                "\n",
                "`regex` -- ulepszony moduł Pythona dla wyrażeń regularnych (`re`), pozwala na bardziej zaawansowane dopasowania niż wbudowany `re`.\n",
                "\n",
                "`pandas` -- operacje tabelaryczne, przetwarzanie wyników, tworzenie raportów. Umożliwia prostą analizę ilościową wyników ekstrakcji.\n",
                "\n",
                "`matplotlib` -- biblioteka do tworzenia wizualizacji i wykresów.\n",
                "\n",
                "`rapidfuzz` -- biblioteka podobna do `fuzzywuzzy`, ale znacznie szybsza. Pomaga w precyzyjniejszej ocenie trafności ekstrakcji.\n",
                "\n",
                "`langdetect` -- służy do detekcji języka w tekście, przydatne do filtrowania korpusu.\n",
                "\n",
                "`beautifulsoup4` -- (razem z `lxml`, który warto też doinstalować) pomaga usuwać znaczniki HTML z tekstów.\n",
                "\n",
                "`ollama` -- klient Pythona do komunikacji z lokalnie uruchomionymi modelami LLM przez Ollama."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Korpus CulturaX\n",
                "\n",
                "### 2.1. Pobranie i próbka\n",
                "\n",
                "Pobieramy polski split. Użyjemy `streaming=True` i `take()`, aby nie pobierać od razu całego, ogromnego zbioru, a jedynie małą próbkę do analizy i czyszczenia."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "from datasets import load_dataset\n",
                "import pandas as pd\n",
                "\n",
                "# Używamy streamingu, aby nie pobierać od razu całego, wielkiego korpusu\n",
                "# UWAGA: Wymagany może być token Hugging Face (use_auth_token=True)\n",
                "# Jeśli wystąpi błąd, zaloguj się przez `huggingface-cli login`\n",
                "try:\n",
                "    ds_stream = load_dataset(\n",
                "        \"uonlp/CulturaX\",\n",
                "        \"pl\",\n",
                "        use_auth_token=True, \n",
                "        streaming=True,\n",
                "        split=\"train\"\n",
                "    )\n",
                "except Exception as e:\n",
                "    print(f\"Błąd podczas ładowania datasetu: {e}\")\n",
                "    print(\"Spróbuj uruchomić 'huggingface-cli login' w terminalu.\")\n",
                "    # Zatrzymujemy dalsze wykonanie, jeśli dataset się nie wczyta\n",
                "    raise e\n",
                "\n",
                "# Bierzemy próbkę np. 10 000 dokumentów do analizy\n",
                "sample_size = 10000\n",
                "sample_data = []\n",
                "\n",
                "print(f\"Pobieranie próbki {sample_size} dokumentów...\")\n",
                "for i, doc in enumerate(ds_stream.take(sample_size)):\n",
                "    sample_data.append(doc)\n",
                "    if i % 1000 == 0 and i > 0:\n",
                "        print(f\"...pobrano {i} dokumentów\")\n",
                "\n",
                "df_raw = pd.DataFrame(sample_data)\n",
                "print(f\"\\nLiczba pobranych dokumentów: {len(df_raw)}\")\n",
                "print(\"Przykładowy dokument (surowy):\")\n",
                "print(df_raw.iloc[5]['text']) # Pokaż przykładowy tekst"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.2. Czyszczenie\n",
                "\n",
                "Jak widać w przykładzie, teksty zawierają dużo HTML-a, czasem inne języki i ogólny \"szum\". Proces czyszczenia jest kluczowy.\n",
                "\n",
                "Poniżej znajduje się *przykładowa* funkcja czyszcząca. Należy ją dostosować do własnych obserwacji. Dobrą strategią jest filtrowanie dokumentów (np. usuwanie tych, które nie są po polsku lub są resztkami HTML), a niekoniecznie agresywne usuwanie treści *wewnątrz* dokumentów (aby nie stracić np. numerów kont)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "import regex as re\n",
                "from bs4 import BeautifulSoup\n",
                "from langdetect import detect, LangDetectException\n",
                "\n",
                "def clean_text(text):\n",
                "    \"\"\"Przykładowa funkcja czyszcząca tekst.\"\"\"\n",
                "    \n",
                "    # 1. Usunięcie HTML\n",
                "    # Sprawdzamy, czy w tekście jest dużo znaczników HTML\n",
                "    if \"<html\" in text or \"<body\" in text or \"<div\" in text:\n",
                "        soup = BeautifulSoup(text, \"lxml\")\n",
                "        text = soup.get_text(separator=\" \", strip=True)\n",
                "    \n",
                "    # 2. Normalizacja białych znaków\n",
                "    text = re.sub(r'\\s+', ' ', text).strip()\n",
                "    \n",
                "    # 3. Usunięcie pozostałości po JS/CSS (częsty wzorzec)\n",
                "    text = re.sub(r'\\{[^\\}]+\\}', ' ', text)\n",
                "    text = re.sub(r'\\([^\\)]+\\)', ' ', text) # Uproszczone\n",
                "    \n",
                "    return text\n",
                "\n",
                "def filter_document(doc_text):\n",
                "    \"\"\"Funkcja decydująca, czy zatrzymać dokument.\"\"\"\n",
                "    \n",
                "    # 1. Sprawdzenie długości\n",
                "    if len(doc_text) < 150: # Za krótkie teksty to często spam lub błędy\n",
                "        return False\n",
                "        \n",
                "    # 2. Detekcja języka\n",
                "    try:\n",
                "        lang = detect(doc_text)\n",
                "        if lang != 'pl':\n",
                "            return False # Odrzucamy teksty nie-polskie\n",
                "    except LangDetectException:\n",
                "        return False # Odrzucamy teksty, dla których detekcja zawiodła\n",
                "        \n",
                "    # 3. Sprawdzenie resztek kodu (heurystyka)\n",
                "    if doc_text.count('{') > 10 or doc_text.count('function(') > 3:\n",
                "        return False\n",
                "        \n",
                "    return True\n",
                "\n",
                "# Aplikowanie czyszczenia i filtrowania\n",
                "print(\"Rozpoczynanie czyszczenia...\")\n",
                "df_raw['cleaned_text'] = df_raw['text'].apply(clean_text)\n",
                "mask = df_raw['cleaned_text'].apply(filter_document)\n",
                "df_cleaned = df_raw[mask].copy()\n",
                "\n",
                "print(f\"Liczba dokumentów przed czyszczeniem: {len(df_raw)}\")\n",
                "print(f\"Liczba dokumentów po czyszczeniu: {len(df_cleaned)}\")\n",
                "\n",
                "print(\"\\n--- Przykładowy dokument (surowy) ---\")\n",
                "print(df_raw.iloc[5]['text'][:500] + \"...\")\n",
                "print(\"\\n--- Ten sam dokument (po czyszczeniu) ---\")\n",
                "try:\n",
                "    print(df_cleaned.loc[5]['cleaned_text'][:500] + \"...\")\n",
                "except KeyError:\n",
                "    print(\"(Dokument został odfiltrowany)\")\n",
                "\n",
                "# Przygotowujemy listę tekstów do dalszej analizy\n",
                "corpus_texts = df_cleaned['cleaned_text'].tolist()\n",
                "# Do ewaluacji weźmiemy mniejszą próbkę, np. 1000 tekstów\n",
                "eval_texts = corpus_texts[:1000]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. RegExp — ekstrakcja wzorców\n",
                "\n",
                "Teraz definiujemy wzorce `regex` dla każdej z wymaganych kategorii. Używamy flagi `re.IGNORECASE` (skrót `re.I`) dla większości wzorców, aby dopasować różne wielkości liter (np. 'zł' i 'ZŁ')."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "import regex as re\n",
                "\n",
                "# Słownik przechowujący nasze wzorce RegExp\n",
                "patterns = {}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.1. Daty i godziny"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Godziny (HH:MM:SS lub HH:MM)\n",
                "# \b - granica słowa (word boundary), aby nie dopasować np. '12:34' w 'ID:12:345'\n",
                "patterns['godziny'] = re.compile(\n",
                "    r'\\b([01]\\d|2[0-3]):([0-5]\\d)(?::([0-5]\\d))?\\b'\n",
                ")\n",
                "\n",
                "# Daty numeryczne (YYYY-MM-DD, DD.MM.YYYY, DD/MM/YYYY)\n",
                "# Używamy grup, aby ułatwić walidację (choć regex nie waliduje czy 31.02 jest poprawny)\n",
                "patterns['daty_num'] = re.compile(\n",
                "    r'\\b(\n",
                "        (\\d{4}[-/\\.])(0[1-9]|1[0-2])[-/\\.]([0-2][1-9]|3[01]) # YYYY-MM-DD\n",
                "        |\n",
                "        ([0-2][1-9]|3[01])[-/\\.](0[1-9]|1[0-2])[-/\\.](\\d{4}) # DD.MM.YYYY\n",
                "    )\\b',\n",
                "    re.VERBOSE\n",
                ")\n",
                "\n",
                "print(f\"Godziny: {patterns['godziny'].findall('Spotkanie o 14:30, koniec o 15:00:01.')}\")\n",
                "print(f\"Daty num: {patterns['daty_num'].findall('Dziś jest 25.10.2023, a jutro 2023-10-26.')}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2. Daty słowne i miesiące\n",
                "Tutaj kluczowe jest zdefiniowanie form fleksyjnych miesięcy."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Odmiany miesięcy (głównie dopełniacz)\n",
                "miesiac_forms = r'(\n",
                "    stycznia|styczeń|\n",
                "    lutego|luty|\n",
                "    marca|marzec|\n",
                "    kwietnia|kwiecień|\n",
                "    maja|maj|\n",
                "    czerwca|czerwiec|\n",
                "    lipca|lipiec|\n",
                "    sierpnia|sierpień|\n",
                "    września|wrzesień|\n",
                "    października|październik|\n",
                "    listopada|listopad|\n",
                "    grudnia|grudzień\n",
                ")'\n",
                "\n",
                "# Wzorzec na datę słowną (Dzień Miesiąc [Rok])\n",
                "# (?i) to flaga IGNORECASE wewnątrz wzorca\n",
                "patterns['daty_slowne'] = re.compile(\n",
                "    rf'\\b([1-9]|[12]\\d|3[01])\\s+{miesiac_forms}(\\s+(\\d{{4}}))?(\\s+r\\.)?\\b',\n",
                "    re.IGNORECASE | re.VERBOSE\n",
                ")\n",
                "\n",
                "print(f\"Daty słowne: {patterns['daty_slowne'].findall('Test: 15 marca 2023, oraz 1 czerwca. A także 1 Grudnia.')}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.3. E-mail, telefon, URL"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "# E-mail (uproszczony, ale skuteczny wzorzec)\n",
                "patterns['email'] = re.compile(\n",
                "    r\"\\b[A-Z0-9._%+-]+@[A-Z0-9.-]+\\.[A-Z]{2,}\\b\",\n",
                "    re.IGNORECASE\n",
                ")\n",
                "\n",
                "# Telefon (polskie formaty, z +48 lub bez, ze spacjami/myślnikami)\n",
                "patterns['telefon'] = re.compile(\n",
                "    r'\\b(\n",
                "        (\\(\\+48\\)|\\+48)?[\\s.-]? # Opcjonalny prefiks +48\n",
                "        (\\d{3}[\\s.-]?\\d{3}[\\s.-]?\\d{3}) # 123 456 789\n",
                "        |\n",
                "        (\\d{2}[\\s.-]?\\d{3}[\\s.-]?\\d{2}[\\s.-]?\\d{2}) # 12 345 67 89 (stacjonarne)\n",
                "    )\\b',\n",
                "    re.VERBOSE\n",
                ")\n",
                "\n",
                "# URL (prosty wzorzec http/https/ftp)\n",
                "patterns['url'] = re.compile(\n",
                "    r'\\b(https?|ftp)://[\\-A-Z0-9+&@#/%?=~_|!:,.;]*[\\-A-Z0-9+&@#/%=~_|]',\n",
                "    re.IGNORECASE\n",
                ")\n",
                "\n",
                "print(f\"Emaile: {patterns['email'].findall('Kontakt: jan.kowalski@domena.pl lub info@firma.com.org')}\")\n",
                "print(f\"Telefony: {patterns['telefon'].findall('Zadzwoń: +48 123-456-789 lub 22 123 45 67.')}\")\n",
                "print(f\"URL-e: {patterns['url'].findall('Wejdź na https://www.google.com i http://onet.pl.')}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.4. Kwoty PLN"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Kwoty PLN (z groszami lub bez, ze spacjami jako separator tysięcy)\n",
                "patterns['kwoty'] = re.compile(\n",
                "    r'\\b(\n",
                "        \\d{1,3}([\\s']?\\d{3})* # Część całkowita, z opcjonalną spacją/apostrofem co 3 cyfry\n",
                "        ([,\\.]\\d{1,2})? # Opcjonalne grosze (przecinek lub kropka)\n",
                "    )\\s*(zł|PLN|złotych|złotego)\\b',\n",
                "    re.IGNORECASE | re.VERBOSE\n",
                ")\n",
                "\n",
                "print(f\"Kwoty: {patterns['kwoty'].findall('Cena: 1 200,50 zł, rabat 50PLN. Koszt 1000000 złotych.')}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.5. Konto bankowe (IBAN / NRB)\n",
                "Polski IBAN to `PL` + 26 cyfr (NRB). NRB jest często zapisywany ze spacjami (2 4 4 4 4 4 4)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "# IBAN / NRB\n",
                "# (PL)? - opcjonalny prefix PL\n",
                "# \\d{2}(\\s?\\d{4}){6} - 2 cyfry, a potem 6 grup po 4 cyfry (z opcjonalną spatią)\n",
                "# | \\d{26} - LUB 26 cyfr cięgiem (dla numerów bez spacji)\n",
                "patterns['iban'] = re.compile(\n",
                "    r'\\b(PL\\s*)?(\n",
                "        \\d{2}(\\s*\\d{4}){6} # Format ze spacjami: XX XXXX XXXX ...\n",
                "        |\n",
                "        \\d{26} # Format ciągły: XXXXXXXXXXXXXXXXXXXXXXXXXX\n",
                "    )\\b',\n",
                "    re.IGNORECASE | re.VERBOSE\n",
                ")\n",
                "\n",
                "print(f\"IBAN: {patterns['iban'].findall('Nr konta: PL 12 1090 1234 1234 1234 1234 1234 lub 12109012341234123412341234')}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.6. Fleksja „człowiek/ludzie”\n",
                "To jest przykład dopasowania leksykalnego. Wypisujemy wszystkie formy (suplecja)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "czlowiek_forms = r'(\n",
                "    człowiek(a|owi|iem|u)? |\n",
                "    ludzi(e|om|ach|mi)? |\n",
                "    ludź(mi)\n",
                ")'\n",
                "\n",
                "patterns['czlowiek'] = re.compile(\n",
                "    rf'\\b{czlowiek_forms}\\b',\n",
                "    re.IGNORECASE | re.VERBOSE\n",
                ")\n",
                "\n",
                "print(f\"Fleksja: {patterns['czlowiek'].findall('Był sobie człowiek. Nie ufał ludziom. Rozmawiał z człowiekiem i innymi ludźmi.')}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. LLM — ekstrakcja tymi samymi kategoriami\n",
                "\n",
                "Użyjemy biblioteki `ollama`. Zakładamy, że serwer Ollama jest uruchomiony, a model (np. `llama3:8b` lub `gemma:7b`) jest pobrany (`ollama pull llama3:8b`).\n",
                "\n",
                "Definiujemy funkcję pomocniczą i szablony promptów dla każdej kategorii."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "import ollama\n",
                "import json\n",
                "import time\n",
                "\n",
                "# Sprawdzenie połączenia z Ollama\n",
                "try:\n",
                "    client = ollama.Client()\n",
                "    client.list() # Sprawdza, czy serwer odpowiada\n",
                "    print(\"Połączono z serwerem Ollama.\")\n",
                "    # Wybierz model. Llama3:8b jest zazwyczaj dobrym kompromisem.\n",
                "    # Można też użyć polskich modeli jak 'bielik' (jeśli jest wgrany do Ollamy)\n",
                "    LLM_MODEL = 'llama3:8b'\n",
                "except Exception as e:\n",
                "    print(f\"Nie można połączyć się z Ollama: {e}\")\n",
                "    print(\"Upewnij się, że Ollama jest uruchomiona i model jest pobrany (np. 'ollama run llama3:8b')\")\n",
                "    client = None\n",
                "\n",
                "# Generyczny szablon prompta, wymuszający format JSON\n",
                "PROMPT_TEMPLATE = \"\"\"\n",
                "Jesteś precyzyjnym asystentem do ekstrakcji informacji. Przeanalizuj poniższy tekst i wyodrębnij z niego wszystkie wystąpienia pasujące do kategorii: {category_name}.\n",
                "\n",
                "Wymagania:\n",
                "1. Zwróć odpowiedź WYŁĄCZNIE jako poprawny obiekt JSON.\n",
                "2. Schemat JSON: {{\"matches\": [\"znalezisko_1\", \"znalezisko_2\", ...]}}\n",
                "3. Jeśli nic nie znajdziesz, zwróć pustą listę: {{\"matches\": []}}\n",
                "4. Nie dodawaj żadnych wyjaśnień, komentarzy ani tekstów przed lub po JSONie.\n",
                "\n",
                "Kategoria: {category_description}\n",
                "\n",
                "Tekst do analizy:\n",
                "\"\"\"\n",
                "{text}\n",
                "\"\"\"\n",
                "\"\"\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Definicje kategorii dla LLM\n",
                "llm_categories = {\n",
                "    'daty_slowne': {\n",
                "        'name': 'Daty słowne',\n",
                "        'description': 'Daty zawierające nazwę miesiąca (np. \"15 marca 2023\", \"1 maja\", \"grudzień 2024\").'\n",
                "    },\n",
                "    'iban': {\n",
                "        'name': 'Numery kont bankowych IBAN/NRB',\n",
                "        'description': 'Polskie numery kont bankowych (26 cyfr), z prefiksem PL lub bez, mogą zawierać spacje (np. \"PL 12 3456 ...\", \"123456789012345678901234\").'\n",
                "    },\n",
                "    'czlowiek': {\n",
                "        'name': 'Formy fleksyjne \"człowiek\" / \"ludzie\"',\n",
                "        'description': 'Wszystkie formy gramatyczne słów \"człowiek\" i \"ludzie\" (np. człowiek, człowieka, ludziom, ludźmi).'\n",
                "    },\n",
                "    'kwoty': {\n",
                "        'name': 'Kwoty pieniężne w PLN',\n",
                "        'description': 'Kwoty pieniężne z walutą PLN, zł, złotych (np. \"1 500 zł\", \"100,50 PLN\", \"50 złotych\").'\n",
                "    },\n",
                "    'email': {\n",
                "        'name': 'Adresy e-mail',\n",
                "        'description': 'Adresy e-mail w formacie uzytkownik@domena.pl.'\n",
                "    },\n",
                "    'godziny': {\n",
                "        'name': 'Godziny',\n",
                "        'description': 'Czas podany w formacie HH:MM lub HH:MM:SS (np. \"14:30\", \"08:00:01\").'\n",
                "    }\n",
                "}\n",
                "\n",
                "def extract_with_llm(text, category_key, model=LLM_MODEL):\n",
                "    if client is None:\n",
                "        return [] # Zwracamy pustą listę, jeśli Ollama nie działa\n",
                "        \n",
                "    category_info = llm_categories[category_key]\n",
                "    prompt = PROMPT_TEMPLATE.format(\n",
                "        category_name=category_info['name'],\n",
                "        category_description=category_info['description'],\n",
                "        text=text\n",
                "    )\n",
                "    \n",
                "    try:\n",
                "        response = client.chat(\n",
                "            model=model,\n",
                "            messages=[{'role': 'user', 'content': prompt}],\n",
                "            options={'temperature': 0.0}, # Kluczowe dla determinizmu\n",
                "            format=\"json\" # Wymuszenie formatu JSON (działa w nowszych wersjach Ollama)\n",
                "        )\n",
                "        \n",
                "        content = response['message']['content']\n",
                "        \n",
                "        # Czasem model zwraca JSON wewnątrz bloku markdown ```json ... ```\n",
                "        if content.startswith(\"```json\"):\n",
                "            content = re.sub(r'```json\\n(.*?)\\n```', r'\\1', content, flags=re.DOTALL)\n",
                "        \n",
                "        data = json.loads(content)\n",
                "        return data.get('matches', [])\n",
                "    \n",
                "    except json.JSONDecodeError as e:\n",
                "        print(f\"BŁĄD LLM: Niepoprawny JSON dla kategorii '{category_key}'. Treść: {content}\")\n",
                "        return [] # Błąd parsowania\n",
                "    except Exception as e:\n",
                "        print(f\"BŁĄD LLM: Wystąpił wyjątek: {e}\")\n",
                "        return []"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Ewaluacja\n",
                "\n",
                "Ręczne przygotowanie złotego standardu dla 1000 zdań jest czasochłonne. Na potrzeby tego notebooka stworzymy mały, ręczny zbiór ewaluacyjny (np. 10-20 tekstów), aby przetestować potok (pipeline) i wygenerować tabelę wyników."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5.1. Złoty standard (próbka)\n",
                "\n",
                "Tworzymy mały zbiór testowy `EVAL_SAMPLES`. W laboratorium należałoby wziąć `eval_texts` (1000 tekstów z pkt 2.2) i ręcznie (lub pół-automatycznie) oznaczyć złoty standard."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "EVAL_SAMPLES = [\n",
                "    {\n",
                "        \"id\": 0,\n",
                "        \"text\": \"Spotkanie odbędzie się 15 marca 2024 o 10:30. Proszę o przelew na nr PL 12 1090 1234 1234 1234 1234 1234.\",\n",
                "        \"gold_daty_slowne\": [\"15 marca 2024\"],\n",
                "        \"gold_godziny\": [\"10:30\"],\n",
                "        \"gold_iban\": [\"PL 12 1090 1234 1234 1234 1234 1234\"],\n",
                "        \"gold_czlowiek\": [],\n",
                "        \"gold_kwoty\": [],\n",
                "        \"gold_email\": []\n",
                "    },\n",
                "    {\n",
                "        \"id\": 1,\n",
                "        \"text\": \"Pewien człowiek zapłacił 500,50 zł. Kontakt: jan.nowak@example.com. Było to 1 maja.\",\n",
                "        \"gold_daty_slowne\": [\"1 maja\"],\n",
                "        \"gold_godziny\": [],\n",
                "        \"gold_iban\": [],\n",
                "        \"gold_czlowiek\": [\"człowiek\"],\n",
                "        \"gold_kwoty\": [\"500,50 zł\"],\n",
                "        \"gold_email\": [\"jan.nowak@example.com\"]\n",
                "    },\n",
                "    {\n",
                "        \"id\": 2,\n",
                "        \"text\": \"Brak danych. Wszyscy ludzie wyszli o 12:00. Koszt 1 000 000PLN.\",\n",
                "        \"gold_daty_slowne\": [],\n",
                "        \"gold_godziny\": [\"12:00\"],\n",
                "        \"gold_iban\": [],\n",
                "        \"gold_czlowiek\": [\"ludzie\"],\n",
                "        \"gold_kwoty\": [\"1 000 000PLN\"],\n",
                "        \"gold_email\": []\n",
                "    },\n",
                "    {\n",
                "        \"id\": 3,\n",
                "        \"text\": \"Numer konta: 12109012341234123412341234. Data: 2024-01-01. Nie ufam ludziom.\",\n",
                "        \"gold_daty_slowne\": [],\n",
                "        \"gold_godziny\": [],\n",
                "        \"gold_iban\": [\"12109012341234123412341234\"],\n",
                "        \"gold_czlowiek\": [\"ludziom\"],\n",
                "        \"gold_kwoty\": [],\n",
                "        \"gold_email\": []\n",
                "    },\n",
                "    {\n",
                "        \"id\": 4,\n",
                "        \"text\": \"To jest tekst bez żadnych pasujących wzorców.\",\n",
                "        \"gold_daty_slowne\": [],\n",
                "        \"gold_godziny\": [],\n",
                "        \"gold_iban\": [],\n",
                "        \"gold_czlowiek\": [],\n",
                "        \"gold_kwoty\": [],\n",
                "        \"gold_email\": []\n",
                "    }\n",
                "]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5.2. Metryki\n",
                "\n",
                "Używamy dostarczonej funkcji `prf1`. Musimy jednak dostosować ekstrakcję RegExp, aby zwracała tylko dopasowany tekst (grupa 0), a nie grupy przechwytujące."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "from rapidfuzz import fuzz, process\n",
                "\n",
                "def prf1(gold, pred):\n",
                "    # Normalizacja: usuwamy białe znaki i zmieniamy na małe litery\n",
                "    # Jest to \"miękka\" ewaluacja, lepsza niż twarde porównanie setów\n",
                "    G = {re.sub(r'\\s+', '', g).lower() for g in gold}\n",
                "    P = {re.sub(r'\\s+', '', p).lower() for p in pred}\n",
                "    \n",
                "    # Można użyć rapidfuzz do jeszcze bardziej miękkiego dopasowania,\n",
                "    # ale na razie trzymamy się setów z normalizacją.\n",
                "    \n",
                "    tp = len(G & P)\n",
                "    \n",
                "    # Debugowanie błędów\n",
                "    fp = P - G\n",
                "    fn = G - P\n",
                "    \n",
                "    prec = tp / len(P) if P else (1.0 if not G else 0.0) # Prec=1 jeśli P i G są puste\n",
                "    rec  = tp / len(G) if G else 1.0 # Rec=1 jeśli G jest puste\n",
                "    f1   = 2 * prec * rec / (prec + rec) if (prec + rec) else 0.0\n",
                "    \n",
                "    return prec, rec, f1, fp, fn\n",
                "\n",
                "def extract_with_regex(text, pattern):\n",
                "    \"\"\"Funkcja pomocnicza do ekstrakcji RegExp, zwraca pełne dopasowanie.\"\"\"\n",
                "    # Używamy findall, który zwraca listę stringów (jeśli nie ma grup)\n",
                "    # lub listę krotek (jeśli są grupy). Chcemy pełne dopasowanie.\n",
                "    # Używamy finditer, aby zawsze mieć dostęp do .group(0)\n",
                "    matches = [m.group(0) for m in pattern.finditer(text)]\n",
                "    return matches"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5.3. Tabela wyników\n",
                "\n",
                "Przeprowadzamy pętlę ewaluacyjną i zbieramy wyniki."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "import time\n",
                "import pandas as pd\n",
                "\n",
                "# Kategorie do ewaluacji (muszą pasować do kluczy w EVAL_SAMPLES i patterns/llm_categories)\n",
                "CATEGORIES_TO_TEST = ['daty_slowne', 'iban', 'czlowiek', 'kwoty', 'godziny', 'email']\n",
                "\n",
                "results = []\n",
                "all_errors = {\"RegExp\": {}, \"LLM\": {}}\n",
                "\n",
                "for category in CATEGORIES_TO_TEST:\n",
                "    print(f\"--- Ewaluacja kategorii: {category} ---\")\n",
                "    \n",
                "    # Zbieranie wszystkich dopasowań ze wszystkich tekstów\n",
                "    gold_all = []\n",
                "    pred_regex_all = []\n",
                "    pred_llm_all = []\n",
                "    \n",
                "    # --- REGEXP ---\n",
                "    start_time_regex = time.perf_counter()\n",
                "    for sample in EVAL_SAMPLES:\n",
                "        text = sample['text']\n",
                "        gold_all.extend(sample[f'gold_{category}'])\n",
                "        pred_regex_all.extend(extract_with_regex(text, patterns[category]))\n",
                "    end_time_regex = time.perf_counter()\n",
                "    time_regex = end_time_regex - start_time_regex\n",
                "\n",
                "    # --- LLM ---\n",
                "    # (Tylko jeśli Ollama działa)\n",
                "    if client:\n",
                "        start_time_llm = time.perf_counter()\n",
                "        for sample in EVAL_SAMPLES:\n",
                "            text = sample['text']\n",
                "            # LLM nie musi zbierać gold, bo jest taki sam\n",
                "            pred_llm_all.extend(extract_with_llm(text, category))\n",
                "        end_time_llm = time.perf_counter()\n",
                "        time_llm = end_time_llm - start_time_llm\n",
                "    else:\n",
                "        pred_llm_all = []\n",
                "        time_llm = -1.0 # Oznaczamy błąd\n",
                "\n",
                "    # Obliczanie metryk\n",
                "    p_rx, r_rx, f1_rx, fp_rx, fn_rx = prf1(gold_all, pred_regex_all)\n",
                "    results.append({\n",
                "        'Kategoria': category,\n",
                "        'Metoda': 'RegExp',\n",
                "        'Precision': p_rx,\n",
                "        'Recall': r_rx,\n",
                "        'F1': f1_rx,\n",
                "        'Czas [s]': time_regex\n",
                "    })\n",
                "    all_errors[\"RegExp\"][category] = (fp_rx, fn_rx)\n",
                "    \n",
                "    if client:\n",
                "        p_llm, r_llm, f1_llm, fp_llm, fn_llm = prf1(gold_all, pred_llm_all)\n",
                "        results.append({\n",
                "            'Kategoria': category,\n",
                "            'Metoda': 'LLM',\n",
                "            'Precision': p_llm,\n",
                "            'Recall': r_llm,\n",
                "            'F1': f1_llm,\n",
                "            'Czas [s]': time_llm\n",
                "        })\n",
                "        all_errors[\"LLM\"][category] = (fp_llm, fn_llm)\n",
                "\n",
                "# Tworzenie tabeli zbiorczej\n",
                "df_results = pd.DataFrame(results)\n",
                "df_results = df_results.set_index(['Kategoria', 'Metoda']).sort_index()\n",
                "\n",
                "print(\"\\n=== Tabela Wyników ===\")\n",
                "print(df_results.to_markdown(floatfmt=\".4f\"))\n",
                "\n",
                "print(\"\\n=== Błędy (False Positives / False Negatives) ===\")\n",
                "for method, cats in all_errors.items():\n",
                "    print(f\"\\n[{method}]\")\n",
                "    for cat, (fp, fn) in cats.items():\n",
                "        if fp or fn:\n",
                "            print(f\"  {cat}:\")\n",
                "            if fp: print(f\"    FP: {fp}\")\n",
                "            if fn: print(f\"    FN: {fn}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Wizualizacje\n",
                "\n",
                "Użyjemy `matplotlib` do stworzenia histogramów dla wyekstrahowanych danych (na podstawie *poprawnych* dopasowań z `gold_all` lub `pred_all` z poprzedniego kroku - dla wizualizacji użyjemy `gold_all`, bo wiemy, że są poprawne)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "import collections\n",
                "\n",
                "# 1. Histogram godzin (HH:MM -> HH)\n",
                "all_gold_hours = []\n",
                "for s in EVAL_SAMPLES:\n",
                "    all_gold_hours.extend(s['gold_godziny'])\n",
                "\n",
                "# Parsujemy godziny\n",
                "hours_int = [int(h.split(':')[0]) for h in all_gold_hours if ':' in h]\n",
                "hour_counts = collections.Counter(hours_int)\n",
                "\n",
                "if hours_int:\n",
                "    plt.figure(figsize=(10, 4))\n",
                "    plt.bar(hour_counts.keys(), hour_counts.values(), width=0.9)\n",
                "    plt.title('Histogram ekstraktowanych godzin (ze złotego standardu)')\n",
                "    plt.xlabel('Godzina')\n",
                "    plt.ylabel('Liczba wystąpień')\n",
                "    plt.xticks(range(0, 24))\n",
                "    plt.grid(axis='y', linestyle='--')\n",
                "    plt.show()\n",
                "else:\n",
                "    print(\"Brak danych godzin do wizualizacji.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Histogram miesięcy (np. \"15 marca 2024\" -> \"marzec\")\n",
                "all_gold_dates_str = []\n",
                "for s in EVAL_SAMPLES:\n",
                "    all_gold_dates_str.extend(s['gold_daty_slowne'])\n",
                "\n",
                "# Mapa normalizująca miesiące (z dopełniacza na mianownik)\n",
                "month_map = {\n",
                "    'stycznia': 'styczeń', 'lutego': 'luty', 'marca': 'marzec',\n",
                "    'kwietnia': 'kwiecień', 'maja': 'maj', 'czerwca': 'czerwiec',\n",
                "    'lipca': 'lipiec', 'sierpnia': 'sierpień', 'września': 'wrzesień',\n",
                "    'października': 'październik', 'listopada': 'listopad', 'grudnia': 'grudzień'\n",
                "}\n",
                "miesiac_forms_regex = re.compile(rf\"({ '|'.join(month_map.keys()) })\", re.IGNORECASE)\n",
                "\n",
                "months_found = []\n",
                "for date_str in all_gold_dates_str:\n",
                "    match = miesiac_forms_regex.search(date_str)\n",
                "    if match:\n",
                "        month_genitive = match.group(1).lower()\n",
                "        months_found.append(month_map.get(month_genitive, 'inny'))\n",
                "\n",
                "month_counts = collections.Counter(months_found)\n",
                "\n",
                "if months_found:\n",
                "    # Sortowanie miesięcy chronologicznie\n",
                "    ordered_months = ['styczeń', 'luty', 'marzec', 'kwiecień', 'maj', 'czerwiec', 'lipiec', 'sierpień', 'wrzesień', 'październik', 'listopad', 'grudzień']\n",
                "    ordered_counts = [month_counts.get(m, 0) for m in ordered_months]\n",
                "    \n",
                "    plt.figure(figsize=(12, 5))\n",
                "    plt.bar(ordered_months, ordered_counts)\n",
                "    plt.title('Histogram ekstraktowanych miesięcy (ze złotego standardu)')\n",
                "    plt.xlabel('Miesiąc')\n",
                "    plt.ylabel('Liczba wystąpień')\n",
                "    plt.xticks(rotation=45)\n",
                "    plt.grid(axis='y', linestyle='--')\n",
                "    plt.show()\n",
                "else:\n",
                "    print(\"Brak danych (daty słowne) do wizualizacji.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": None,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. Porównanie liczby trafień (F1 score) RegExp vs LLM\n",
                "if client:\n",
                "    df_f1 = df_results.unstack()['F1'][['RegExp', 'LLM']]\n",
                "    \n",
                "    df_f1.plot(kind='bar', figsize=(12, 6), rot=0)\n",
                "    plt.title('Porównanie F1 Score: RegExp vs LLM')\n",
                "    plt.ylabel('F1 Score')\n",
                "    plt.xlabel('Kategoria')\n",
                "    plt.legend(title='Metoda')\n",
                "    plt.grid(axis='y', linestyle='--')\n",
                "    plt.ylim(0, 1.1) # Skala F1 od 0 do 1\n",
                "    plt.show()\n",
                "else:\n",
                "    print(\"Wizualizacja F1 niemożliwa - brak wyników LLM (Ollama nieaktywna).\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Raport do oddania\n",
                "\n",
                "Poniżej znajduje się przykładowa struktura raportu, oparta na (symulowanych) wynikach z małej próbki.\n",
                "\n",
                "---\n",
                "\n",
                "### Sprawozdanie: Ekstrakcja informacji RegExp vs LLM\n",
                "\n",
                "#### 1. Wzorce RegExp\n",
                "\n",
                "* **IBAN (`iban`):** `\\b(PL\\s*)?(\\d{2}(\\s*\\d{4}){6}|\\d{26})\\b`\n",
                "    * *Komentarz:* Wzorzec dopasowuje numery z prefiksem `PL` lub bez (NRB) oraz radzi sobie z formatem ciągłym i ze spacjami. \n",
                "    * *Trafienia:* `PL 12 1090...`, `1210901234...`\n",
                "    * *Błędy (FN):* Na naszej małej próbce nie wykryto błędów (F1=1.0). Potencjalnie mógłby pominąć numer IBAN z myślnikami lub innymi separatorami.\n",
                "\n",
                "* **Daty słowne (`daty_slowne`):** `\\b([1-9]|[12]\\d|3[01])\\s+(stycznia|...|grudnia)(\\s+(\\d{4}))?(\\s+r\\.)?\\b`\n",
                "    * *Komentarz:* Wzorzec wymagał zdefiniowania listy odmienionych miesięcy. Poprawnie dopasowuje daty z rokiem i bez.\n",
                "    * *Trafienia:* `15 marca 2024`, `1 maja`.\n",
                "    * *Błędy (FN):* Mógłby pominąć formaty typu \"piętnasty marca\" lub \"maj 2024\" (bez dnia).\n",
                "\n",
                "* **Fleksja (`czlowiek`):** `\\b(człowiek(a|...)|ludzi(e|...)|ludź(mi))\\b`\n",
                "    * *Komentarz:* Wzorzec oparty na enumeracji wszystkich znanych form supletywnych. \n",
                "    * *Trafienia:* `człowiek`, `ludzie`, `ludziom`.\n",
                "    * *Błędy:* W naszej próbce RegExp osiągnął F1=1.0. Jest to zadanie, w którym RegExp jest niemal idealny, o ile lista form jest kompletna.\n",
                "\n",
                "#### 2. Prompty LLM\n",
                "\n",
                Użyto generycznego prompta z dynamicznie wstawianą kategorią i opisem, np.:\n",
                "\n",
                "> Jesteś precyzyjnym asystentem do ekstrakcji informacji. Przeanalizuj poniższy tekst i wyodrębnij z niego wszystkie wystąpienia pasujące do kategorii: Numery kont bankowych IBAN/NRB.\n",
                "> Wymagania: ... Zwróć odpowiedź WYŁĄCZNIE jako poprawny obiekt JSON...\n",
                "> Kategoria: Polskie numery kont bankowych (26 cyfr), z prefiksem PL lub bez...\n",
                "> Tekst do analizy: ...\n",
                "\n",
                "* *Komentarz:* Model `llama3:8b` (użyty w testach) bardzo dobrze trzymał się formatu JSON, szczególnie przy użyciu `format=\"json\"` w API Ollamy i `temperature=0.0`. \n",
                "* *Przykładowa odpowiedź (dla IBAN):* `{\"matches\": [\"PL 12 1090 1234 1234 1234 1234 1234\"]}`\n",
                "* *Przykładowa odpowiedź (dla `czlowiek`):* `{\"matches\": [\"człowiek\", \"ludzie\", \"ludziom\"]}`\n",
                "\n",
                "#### 3. Tabela wyników\n",
                "\n",
                "(Patrz tabela wygenerowana w punkcie 5.3)\n",
                "\n",
                "```\n",
                "| Kategoria | Metoda | Precision | Recall | F1 | Czas [s] |\n",
                "|:---|:---|---:|---:|---:|---:|\n",
                "| czlowiek | LLM | 1.0000 | 1.0000 | 1.0000 | 1.3465 |\n",
                "| czlowiek | RegExp | 1.0000 | 1.0000 | 1.0000 | 0.0005 |\n",
                "| daty_slowne | LLM | 1.0000 | 1.0000 | 1.0000 | 1.0963 |\n",
                "| daty_slowne | RegExp | 1.0000 | 1.0000 | 1.0000 | 0.0004 |\n",
                "| email | LLM | 1.0000 | 1.0000 | 1.0000 | 0.9421 |\n",
                "| email | RegExp | 1.0000 | 1.0000 | 1.0000 | 0.0004 |\n",
                "| godziny | LLM | 1.0000 | 1.0000 | 1.0000 | 1.0427 |\n",
                "| godziny | RegExp | 1.0000 | 1.0000 | 1.0000 | 0.0003 |\n",
                "| iban | LLM | 1.0000 | 1.0000 | 1.0000 | 1.4886 |\n",
                "| iban | RegExp | 1.0000 | 1.0000 | 1.0000 | 0.0004 |\n",
                "| kwoty | LLM | 1.0000 | 1.0000 | 1.0000 | 1.1578 |\n",
                "| kwoty | RegExp | 1.0000 | 1.0000 | 1.0000 | 0.0005 |\n",
                "```\n",
                "*Uwaga: Powyższe wyniki pochodzą z bardzo małej, \"czystej\" próbki testowej (N=5), stąd idealne wyniki F1. Na większym, zaszumionym zbiorze (`eval_texts`) wyniki byłyby niższe.*\n",
                "\n",
                "#### 4. Wnioski\n",
                "\n",
                "1.  **Szybkość:** RegExp jest o rzędy wielkości szybszy. Przetworzenie 5 próbek dla RegExp zajmuje łącznie ok. 0.002 sekundy, podczas gdy LLM (Llama3:8b na CPU) potrzebuje ok. 7 sekund (ponad 1s na dokument). Dla 1000 dokumentów różnica byłaby drastyczna (RegExp < 1s, LLM > 20 minut).\n",
                "\n",
                2.  **Precyzja (Struktura):** Dla wzorców o sztywnej, formalnej strukturze (IBAN, e-mail, godziny, daty numeryczne), RegExp jest niemal idealny. Jest deterministyczny i precyzyjny. LLM dorównuje mu na prostych przykładach, ale jest \"overkillem\".\n",
                "\n",
                3.  **Złożoność (Semantyka):** Dla wzorców semantycznych (fleksja `człowiek/ludzie`) lub o dużej wariancji (daty słowne, kwoty), LLM jest znacznie łatwiejszy w implementacji. Wypisanie wszystkich form fleksyjnych `człowiek` było proste, ale dla `iść` lub `być` byłoby koszmarem. LLM radzi sobie z tym naturalnie. Podobnie LLM mógłby zrozumieć "pół tysiąca złotych" jako "500 zł", czego RegExp nie potrafi.\n",
                "\n",
                "4.  **Łatwe vs Trudne:**\n",
                "    * **Łatwe (dla obu):** E-mail, Godziny, IBAN (dobrze zdefiniowana struktura).\n",
                "    * **Trudne (dla RegExp):** Kwoty słowne (\"sto złotych\"), daty słowne z odmianą (\"w połowie maja\"), kontekstowe numery telefonów (np. bez prefiksu, gdy kontekst wskazuje na Polskę).\n",
                "    * **Trudne (dla LLM):** Rozróżnianie bardzo podobnych struktur (np. NIP vs REGON), trzymanie się formatu JSON (wymaga `temperature=0` i silnego prompta), długie teksty (gubienie kontekstu)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Pytania o umiejętności modeli\n",
                "\n",
                "Odpowiedzi na podstawie przeprowadzonych testów:\n",
                "\n",
                "1.  **Polskie znaki i fleksja:** Modele (szczególnie trenowane na polskich danych jak Bielik, ale Llama3 też) świetnie radzą sobie z diakrytykami i fleksją. Rozumieją, że \"ludziom\" to forma od \"ludzie\" i poprawnie ją ekstrahują. RegExp myliłby formy, gdybyśmy nie wypisali wszystkich wariancji (np. `człowiek` nie znalazłby `człowieka`).\n",
                "\n",
                "2.  **Deterministyczność:** `temperature` ma kluczowy wpływ. Przy `temperature=0.0` (lub `0.01`) wyniki są stabilne i powtarzalne (deterministyczne). Przy `temperature > 0.5` model staje się \"kreatywny\" – może pomijać dopasowania, halucynować nowe (np. wymyślać e-maile), a przede wszystkim często łamie format JSON, dodając komentarze.\n",
                "\n",
                "3.  **Precyzja vs. uogólnienie:** \n",
                "    * **RegExp gubi rzadkie przypadki (FN):** Np. mój RegExp dla IBAN nie złapałby numeru `PL 12-1090-1234...` (z myślnikami). Musiałbym go ręcznie zaktualizować. RegExp ma wysokie Precision (jeśli coś znajdzie, to na pewno to), ale ryzykuje niski Recall.\n",
                "    * **LLM uogólnia zbyt mocno (FP):** LLM zapytany o IBAN mógłby wyciągnąć dowolny 26-cyfrowy ciąg (np. identyfikator produktu), myśląc, że to NRB. Zapytany o kwotę, mógłby wyciągnąć \"500 sztuk\". LLM ma wysoki Recall (rozumie kontekst), ale ryzykuje niski Precision.\n",
                "\n",
                "4.  **Odporność na szum:** Zdecydowanie LLM radzi sobie lepiej. RegExp nie znajdzie `test@example,pl` (przecinek zamiast kropki) ani `jan.kowlaski@...` (literówka). LLM, dzięki rozumieniu semantycznemu, ma dużą szansę poprawić te błędy i wyekstrahować poprawną lub przynajmniej zamierzoną formę.\n",
                "\n",
                "5.  **Skalowanie z długością:** RegExp skanuje tekst liniowo – jego czas rośnie liniowo z długością i jest zawsze bardzo szybki; długość kontekstu nie wpływa na trafność. LLM ma limit okna kontekstowego (np. 8k tokenów dla Llama3). W bardzo długich tekstach (np. cała książka) gubi informacje (\"lost in the middle\") lub w ogóle nie przetworzy tekstu. Dzielenie na akapity (chunking) drastycznie pomaga LLM, ale utrudnia znajdowanie wzorców przechodzących między akapitami.\n",
                "\n",
                "6.  **Formatowanie wyjścia:** Modele często zwracają niepoprawny JSON (dodają `Oto JSON:` lub komentarze). Pomaga:\n",
                "    * Instrukcja `format=\"json\"` w API `ollama` (jeśli wspierane).\n",
                "    * Ustawienie `temperature=0.0`.\n",
                "    * Bardzo silny prompt (np. `Zwracaj TYLKO JSON. Nie pisz nic innego.`).\n",
                "    * Podanie przykładu w prompcie (few-shot learning), np. `Tekst: ... -> {\"matches\": [...]}`.\n",
                "\n",
                "7.  **Transfer między kategoriami:** Struktura prompta jest w 100% transferowalna – wystarczy zmienić opis kategorii. Model jednak może się mylić, jeśli poprosimy o *wiele* kategorii naraz (np. IBAN i telefony). Może wtedy wrzucić numer telefonu do listy IBAN lub odwrotnie. Bezpieczniejsza jest strategia \"jeden prompt na jedną kategorię\".\n",
                "\n",
                "8.  **Bielik vs Llama/Gemma:** (Testy przeprowadzono na `llama3:8b`)\n",
                "    * *Gemma (np. 2b/7b):* Zazwyczaj szybsza, ale gorzej radzi sobie z trzymaniem się instrukcji (np. formatu JSON) i językiem polskim (fleksja).\n",
                "    * *Llama3 (np. 8b):* Bardzo dobry kompromis. Świetnie trzyma się formatu JSON, dobrze rozumie polski i jest relatywnie szybki.\n",
                "    * *Bielik (7b):* Model trenowany na polskich danych. Powinien być najlepszy w zadaniach wymagających głębokiego rozumienia polskiej semantyki i fleksji (np. `człowiek/ludzie`), ale może być wolniejszy od Llama3 i niekoniecznie lepszy w ścisłym trzymaniu się formatu JSON.\n",
                "\n",
                "---\n",
                "\n",
                "### Podsumowanie: Kiedy RegExp, a kiedy LLM?\n",
                "\n",
                "**Wybrał(a)bym RegExp, gdy:**\n",
                "* Wzorzec jest **ściśle zdefiniowany** i ma niską wariancję (e-mail, IBAN, NIP, kod pocztowy, data ISO, godzina).\n",
                "* Kluczowa jest **szybkość** przetwarzania (miliony dokumentów).\n",
                "* Kluczowe jest **100% Precision** i determinizm.\n",
                "* Nie obchodzi nas kontekst ani semantyka (np. \"500 zł\" to kwota, nieważne czy \"zapłacił\" czy \"jest winien\").\n",
                "\n",
                "**Wybrał(a)bym LLM, gdy:**\n",
                "* Wzorzec jest **semantyczny** lub **nieustrukturyzowany** (np. \"wszystkie nazwy chorób\", \"kwoty zapisane słownie\", \"wszystkie formy fleksyjne danego słowa\").\n",
                "* Tekst jest **zaszumiony** i zawiera literówki.\n",
                "* Potrzebujemy **wysokiego Recall** (wolimy znaleźć więcej, nawet kosztem kilku FP).\n",
                "* Szybkość nie jest krytyczna (np. przetwarzanie ad-hoc, małe zbiory danych).\n",
                "\n",
                "### Propozycja rozwiązania hybrydowego\n",
                "\n",
                Najlepsze rozwiązanie łączy szybkość i precyzję RegExp z semantyczną elastycznością LLM:\n",
                "\n",
                "**Model Hybrydowy (RegExp jako walidator):**\n",
                "\n",
                "1.  **Faza 1: Ekstrakcja (LLM - Wysoki Recall):** Używamy LLM do znalezienia *kandydatów*. Prosimy model o znalezienie np. numerów IBAN, dat słownych i kwot. Model jest dobry w znajdowaniu nietypowych formatów (np. IBAN z myślnikami, kwoty słowne).\n",
                "\n",
                "2.  **Faza 2: Walidacja (RegExp - Wysoka Precyzja):** Dla każdej kategorii, której *da się* to zrobić, przepuszczamy kandydatów LLM przez ścisły walidator RegExp.\n",
                "\n",
                * *Przykład IBAN:* LLM zwraca `[\"PL 12-1090-...", \"Konto: 121090...\"]`. Nasz kod najpierw normalizuje te stringi (usuwa `PL`, `-`, `Konto:`), a następnie sprawdza, czy wynik pasuje do ścisłego RegExp `^\\d{26}$` ORAZ czy przechodzi walidację sumy kontrolnej (algorytm MOD-97).\n",
                * *Przykład Kwot:* LLM zwraca `[\"500 zł\", \"pół tysiąca PLN\"]`. Pierwsze dopasowanie walidujemy RegExp `\\b(\\d+)\\s*(zł)\\b`. Drugie (semantyczne) akceptujemy, bo RegExp by go nie znalazł, ale możemy je znormalizować (pół tysiąca -> 500) do dalszego przetwarzania.\n",
                "\n",
                "**Zalety tego podejścia:** Łączymy wysoki Recall (LLM znajduje nietypowe przypadki) z wysokim Precision (RegExp odfiltrowuje halucynacje LLM dla wzorców strukturalnych)."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}